{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets used in the analysis for J. Davis et al. \"Ocean surface wave slopes and wind-wave alignment observed in Hurricane Idalia\".\n",
    "\n",
    "All data are available at the Dryad repository for this publication (https://doi.org/10.5061/dryad.zw3r228h7) and at the Dryad repository for Davis et al. (2023) (https://doi.org/10.5061/dryad.g4f4qrfvb). See `input_data/README.md`.\n",
    "\n",
    "Paths are saved in `config.toml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from configure import get_config\n",
    "from src import best_track, buoy_accessor, met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the configuration file, `config.toml`, which contains the data directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables are shared across notebooks using the IPython \"magic\" commands `%store` to save variables and `%store -r` to read them.\n",
    "The following cell clears all stored variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis start and end time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and store the time periods which will be used in the analysis. This includes a longer time period `time_slice_full` which will be used to trim the datasets to a period covering a day leading up to the storm and part of the day after the storm has passed, and `time_slice`, a 15-hour period centered on Idalia's point of closest approach to the buoy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'time_slice_full' (slice)\n",
      "Stored 'time_slice_full_no_tz' (slice)\n"
     ]
    }
   ],
   "source": [
    "start_date = pd.Timestamp('2023-08-29T00:00', tz='utc')\n",
    "end_date = pd.Timestamp('2023-08-31T00:00', tz='utc')\n",
    "time_slice_full = slice(start_date, end_date)\n",
    "time_slice_full_no_tz = slice(start_date.tz_localize(None), end_date.tz_localize(None))\n",
    "\n",
    "%store time_slice_full\n",
    "%store time_slice_full_no_tz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the shorter, 15-hour `time_slice` period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'time_slice' (slice)\n",
      "Stored 'time_slice_no_tz' (slice)\n"
     ]
    }
   ],
   "source": [
    "start_date = pd.Timestamp('2023-08-30T00:00', tz='utc')\n",
    "end_date = pd.Timestamp('2023-08-30T15:00', tz='utc')\n",
    "time_slice = slice(start_date, end_date)\n",
    "time_slice_no_tz = slice(start_date.tz_localize(None), end_date.tz_localize(None))\n",
    "\n",
    "%store time_slice\n",
    "%store time_slice_no_tz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drifter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the microSWIFT and Spotter drifter datasets and concatenate them into a single DataFrame, `drifter_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_drifters(drifter_dict: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Concatenate a dictionary of individual drifter DataFrames into a single,\n",
    "    multi-index DataFrame.  Drop the observations that do not contain waves\n",
    "    (remove off-hour pressure and temperature observations).\n",
    "\n",
    "    Args:\n",
    "        drifter_dict (dict): individual drifter DataFrames keyed by id.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: concatenated drifters\n",
    "    \"\"\"\n",
    "    drifter_df = (\n",
    "        pd.concat(drifter_dict, names=['id', 'time'])\n",
    "        .dropna(subset='energy_density')\n",
    "    )\n",
    "    return drifter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'drifter_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "DRIFTER_DATA_PATH = config['dir']['idalia_drifter_data']\n",
    "\n",
    "with open(DRIFTER_DATA_PATH, 'rb') as handle:\n",
    "    drifter_data = pickle.load(handle)\n",
    "\n",
    "# Concatenate the individual drifter DataFrames by type\n",
    "microswift_df = concatenate_drifters(drifter_data['microswift'])\n",
    "spotter_df = concatenate_drifters(drifter_data['spotter'])\n",
    "\n",
    "# Create a drifter type column\n",
    "microswift_df['drifter_type'] = 'microswift'\n",
    "spotter_df['drifter_type'] = 'spotter'\n",
    "\n",
    "# Combine all drifters into a single DataFrame.\n",
    "drifter_df = (pd.concat([microswift_df, spotter_df])\n",
    "              .sort_index(level=['id', 'time'], ascending=True)\n",
    "              .loc[(slice(None), time_slice_full), :])\n",
    "\n",
    "%store drifter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drifter_df.index.get_level_values('id').unique().size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COAMPS-TC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the COAMPS-TC wind fields into a Dataset, `coamps_ds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'coamps_ds' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "# Reanalysis winds\n",
    "COAMPS_PATH = config['dir']['coamps']\n",
    "coamps_ds = xr.open_dataset(COAMPS_PATH)\n",
    "coamps_ds = coamps_ds.rename(\n",
    "    {'lon': 'longitude',\n",
    "     'lat': 'latitude',\n",
    "     'uuwind': 'u',\n",
    "     'vvwind': 'v',\n",
    "     'slpres': 'mslp'})\n",
    "coamps_ds = coamps_ds.sel(time=time_slice_full_no_tz)\n",
    "coamps_ws =  np.sqrt(coamps_ds['u'].values**2 + coamps_ds['v'].values**2)\n",
    "coamps_ds['ws'] = (('time', 'latitude', 'longitude'), coamps_ws)\n",
    "\n",
    "%store coamps_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NHC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load National Hurricane Center shape files (for mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'idalia_nhc_geometry' (tuple)\n"
     ]
    }
   ],
   "source": [
    "BEST_TRACK_DIRECTORY = config['dir']['best_track']\n",
    "idalia_pts = best_track.read_shp_file(BEST_TRACK_DIRECTORY + 'AL102023_pts.shp', index_by_datetime=True)\n",
    "idalia_lin = best_track.read_shp_file(BEST_TRACK_DIRECTORY + 'AL102023_lin.shp')\n",
    "idalia_radii = best_track.read_shp_file(BEST_TRACK_DIRECTORY + 'AL102023_radii.shp')\n",
    "idalia_windswath = best_track.read_shp_file(BEST_TRACK_DIRECTORY + 'AL102023_windswath.shp')\n",
    "\n",
    "idalia_pts = best_track.best_track_pts_to_intensity(idalia_pts)\n",
    "idalia_nhc_geometry = (idalia_pts, idalia_lin, idalia_windswath)\n",
    "\n",
    "%store idalia_nhc_geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFMR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Stepped Frequency Microwave Radiometer (SFMR) data for COAMPS-TC surface wind validation.  The SFMR is flown by both NOAA and the United States Air Force Reserve (USAFR) Weather Reconnaissance Squadron.\n",
    "\n",
    "Flight-level meterological datasets are available at: https://www.aoml.noaa.gov/2023-hurricane-field-program-data/#idalia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: add SFMR to input data on dryad\n",
    "#TODO: update readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'noaa_sfmr_ds' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "NOAA_SFMR_DIRECTORY = config['dir']['noaa_met_data']\n",
    "noaa_met_data_vars = [\n",
    "    'SfmrWS.1', 'SfmrWErr.1', 'SfmrRainRate.1', 'SfmrDV.1',\n",
    "    'LonGPS.1', 'LatGPS.1', 'RollI.1', #'RollI-GPS.1'\n",
    "]\n",
    "#TODO: pitch and roll? Altitude?\n",
    "noaa_met_rename_dict = {\n",
    "    'Time': 'datetime',\n",
    "    'SfmrWS.1': 'sfmr_10m_wind_speed',\n",
    "    'SfmrWErr.1': 'sfmr_10m_wind_speed_error',\n",
    "    'SfmrRainRate.1': 'sfmr_rain_rate',\n",
    "    'SfmrDV.1': 'sfmr_data_validity',\n",
    "    'LonGPS.1': 'longitude',\n",
    "    'LatGPS.1': 'latitude',\n",
    "    'RollI.1': 'roll_angle',\n",
    "}\n",
    "\n",
    "noaa_sfmr_ds = met.read_noaa_met_directory(NOAA_SFMR_DIRECTORY,\n",
    "                                           data_vars=noaa_met_data_vars)\n",
    "noaa_sfmr_ds = noaa_sfmr_ds.rename(noaa_met_rename_dict)\n",
    "\n",
    "%store noaa_sfmr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'usafr_sfmr_ds' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "USAFR_SFMR_DIRECTORY = config['dir']['usafr_met_data']\n",
    "usafr_met_data_vars = [\n",
    "    # 'SWS', 'WSPD', 'WDIR', 'RR', 'LON', 'LAT',\n",
    "    'SWS', 'RR', 'LON', 'LAT', 'ROLL',\n",
    "]\n",
    "#TODO: pitch and roll? Altitude?\n",
    "usafr_met_rename_dict = {\n",
    "    'GMT_Time': 'datetime',\n",
    "    'SWS': 'sfmr_10m_wind_speed_kts',\n",
    "    # 'WSPD': 'flight_level_wind_speed',\n",
    "    # 'WDIR': 'flight_level_wind_direction',\n",
    "    'RR': 'sfmr_rain_rate',\n",
    "    'LON': 'longitude',\n",
    "    'LAT': 'latitude',\n",
    "    'ROLL': 'roll_angle',\n",
    "}\n",
    "\n",
    "usafr_sfmr_ds = met.read_usafr_met_directory(USAFR_SFMR_DIRECTORY,\n",
    "                                             data_vars=usafr_met_data_vars,\n",
    "                                             data_type='xarray')\n",
    "usafr_sfmr_ds = usafr_sfmr_ds.rename(usafr_met_rename_dict)\n",
    "\n",
    "%store usafr_sfmr_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load meteorological data from National Data Buoy Center station 42036 for additional COAMPS-TC surface wind validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'wave_frequency_bounds' has more than 1-dimension and the same name as one of its dimensions ('wave_frequency', 'wave_frequency_bounds'). xarray disallows such variables because they conflict with the coordinates used to label dimensions.\n",
      "Stored 'ndbc_ds' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "NDBC_DATA_PATH = config['dir']['ndbc_data']\n",
    "\n",
    "ndbc_met_data_vars = [\n",
    "    'latitude',\n",
    "    'latitude_qc',\n",
    "    'longitude',\n",
    "    'longitude_qc',\n",
    "    'wind_speed_primary_sensor',\n",
    "    'wind_speed_primary_sensor_qc',\n",
    "    'wind_gust_primary_sensor',\n",
    "    'wind_gust_primary_sensor_qc',\n",
    "    'max_1_minute_wind_speed_primary_sensor',\n",
    "    'max_1_minute_wind_speed_primary_sensor_qc',\n",
    "    'wind_direction_primary_sensor',\n",
    "    'wind_direction_primary_sensor_qc',\n",
    "    'wind_gust_primary_sensor',\n",
    "    'wind_gust_primary_sensor_qc',\n",
    "    'wind_speed_secondary_sensor',\n",
    "    'wind_speed_secondary_sensor_qc',\n",
    "    'wind_direction_secondary_sensor',\n",
    "    'wind_direction_secondary_sensor_qc',\n",
    "    'sea_surface_wave_significant_height',\n",
    "]\n",
    "\n",
    "ndbc_ds = met.read_ndbc_file(NDBC_DATA_PATH, data_vars=ndbc_met_data_vars)\n",
    "ndbc_ds = ndbc_ds.sel(time=time_slice_full_no_tz)\n",
    "\n",
    "%store ndbc_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBTrACS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the International Best Track Archive for Climate Stewardship (IBTrACS) dataset which is used for storm positions and meterological metrics (Knapp et al., 2010; Gahtan et al., 2024).  The dataset is read into Pandas directly from the server.  The dataset is also available at: https://www.ncei.noaa.gov/products/international-best-track-archive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ibtracs_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "IBTRACS_PATH = config['dir']['ibtracs']\n",
    "ibtracs_df = pd.read_csv(IBTRACS_PATH, low_memory=False)\n",
    "ibtracs_df = (ibtracs_df\n",
    "    .query('NAME == \"IDALIA\"')\n",
    "    .query('SEASON == \"2023\"')\n",
    "    .assign(ISO_TIME = lambda df: pd.to_datetime(df['ISO_TIME'], utc=True))\n",
    "    .set_index('ISO_TIME', drop=True)\n",
    "    .assign(LAT = lambda df: df['LAT'].astype(np.float64))\n",
    "    .assign(LON = lambda df: df['LON'].astype(np.float64))\n",
    ")\n",
    "\n",
    "%store ibtracs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEBCO Bathymetry\n",
    "\n",
    "Load bathymetry data for the region containing the buoys (GEBCO Bathymetric Compilation Group, 2023).  The dataset is available at: https://www.gebco.net/data_and_products/gridded_bathymetry_data/.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'bathymetry_ds' (Dataset)\n"
     ]
    }
   ],
   "source": [
    "GEBCO_PATH = config['dir']['gebco']\n",
    "bathymetry_ds = xr.load_dataset(GEBCO_PATH)\n",
    "\n",
    "%store bathymetry_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ian and Fiona from Davis et al. (2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from Davis et al. (2023) \"Saturation of Ocean Surface Wave Slopes Observed During Hurricanes\".\n",
    "\n",
    "The datasets can be downloaded at: https://doi.org/10.5061/dryad.g4f4qrfvb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_davis_data(drifter_df):\n",
    "    drifter_df = (drifter_df\n",
    "        .rename({\n",
    "            'spotter_id': 'id',\n",
    "            'mean_square_slope_unadjusted': 'mean_square_slope_observed',\n",
    "            'COAMPS_10m_wind_speed': 'wind_speed',\n",
    "            'COAMPS_10m_wind_speed_u': 'wind_speed_u',\n",
    "            'COAMPS_10m_wind_speed_v': 'wind_speed_v',\n",
    "        }, axis=1)\n",
    "        .set_index(['id', 'time'])\n",
    "    )\n",
    "    return drifter_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'ian_spotter_coamps_df' (DataFrame)\n",
      "Stored 'fiona_spotter_coamps_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "IAN_PATH = config['dir']['ian_drifter_data']\n",
    "FIONA_PATH = config['dir']['fiona_drifter_data']\n",
    "\n",
    "# Read the data into a pandas.DataFrame and convert the entries in the\n",
    "# 'time' column to datetimes.\n",
    "ian_spotter_coamps_df = pd.read_json(IAN_PATH, convert_dates=['time'])\n",
    "fiona_spotter_coamps_df = pd.read_json(FIONA_PATH, convert_dates=['time'])\n",
    "\n",
    "# Rename variables for consistency\n",
    "ian_spotter_coamps_df = rename_davis_data(ian_spotter_coamps_df)\n",
    "fiona_spotter_coamps_df = rename_davis_data(fiona_spotter_coamps_df)\n",
    "\n",
    "# Map spectral variables to arrays\n",
    "spectral_cols = ian_spotter_coamps_df.buoy.spectral_variables\n",
    "ian_spotter_coamps_df.loc[:, spectral_cols] = ian_spotter_coamps_df[spectral_cols].map(np.array)\n",
    "spectral_cols = fiona_spotter_coamps_df.buoy.spectral_variables\n",
    "fiona_spotter_coamps_df.loc[:, spectral_cols] = fiona_spotter_coamps_df[spectral_cols].map(np.array)\n",
    "\n",
    "%store ian_spotter_coamps_df\n",
    "%store fiona_spotter_coamps_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Davis, J. R., Thomson, J., Houghton, I. A., Doyle, J. D., Komaromi, W. A., Fairall, C. W., Thompson, E. J., & Moskaitis, J. R. (2023). Saturation of Ocean Surface Wave Slopes Observed During Hurricanes. Geophysical Research Letters, 50(16), e2023GL104139. https://doi.org/10.1029/2023GL104139\n",
    "\n",
    "Gahtan, J., Knapp, K. R., Schreck, C. J. I., Diamond, H. J., Kossin, J. P., & Kruk, M. C. (2024). International Best Track Archive for Climate Stewardship (IBTrACS) Project (Version 4.01 (Last 3 years)) [Dataset]. NOAA National Centers for Environmental Information. https://doi.org/doi:10.25921/82ty-9e16\n",
    "\n",
    "GEBCO Bathymetric Compilation Group 2023. (2023). The GEBCO_2023 Grid—A continuous terrain model of the global oceans and land. [Dataset]. NERC EDS British Oceanographic Data Centre NOC. https://doi.org/10.5285/f98b053b-0cbc-6c23-e053-6c86abc0af7b\n",
    "\n",
    "Knapp, K. R., Kruk, M. C., Levinson, D. H., Diamond, H. J., & Neumann, C. J. (2010). The International Best Track Archive for Climate Stewardship (IBTrACS): Unifying Tropical Cyclone Data. Bulletin of the American Meteorological Society, 91(3), 363–376. https://doi.org/10.1175/2009BAMS2755.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocean-surface-wave-slopes-and-wind-wave-alignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
